{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sought-brand",
   "metadata": {},
   "source": [
    "## Assignment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patent-thousand",
   "metadata": {},
   "source": [
    "### Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "roman-plane",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intrinsic  parameters from Left_Cali= \n",
      " [[1.75217083e+03 0.00000000e+00 3.37377746e+02]\n",
      " [0.00000000e+00 1.75518793e+03 2.25045638e+02]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n",
      "Distortion parameters from Left_Cali= \n",
      " [[-4.40812031e-01  3.52324408e-01  5.87232218e-03  3.25912689e-04\n",
      "   5.83560509e+00]] \n",
      "\n",
      "Intrinsic  parameters from Right_Cali= \n",
      " [[1.74935190e+03 0.00000000e+00 3.07413499e+02]\n",
      " [0.00000000e+00 1.75443478e+03 2.08938564e+02]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n",
      "Distortion parameters from Right_Cali= \n",
      " [[-5.28875909e-01  3.68491062e-01  4.57006164e-03  5.58489376e-03\n",
      "   2.69162283e+01]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os \n",
    "\n",
    "def callibrate_camera(imgCategory, cameraName):    \n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)    \n",
    "    objp = np.zeros((7*10,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:10,0:7].T.reshape(-1,2)\n",
    "\n",
    "    objpoints = [] # 3d point in real world space\n",
    "    imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "    imagesFolder = os.path.join(os.getcwd(),'Downloads',str(imgCategory), str(cameraName))\n",
    "    images = [ os.path.join(imagesFolder, f) for f in os.listdir('Downloads/'+ str(imgCategory) +'/'+str(cameraName)) if f.endswith(\".png\") or f.endswith('.bmp')]\n",
    "\n",
    "    for fname in images:\n",
    "        img = cv2.imread(fname)\n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (10,7),None)\n",
    "        if ret == True:\n",
    "            objpoints.append(objp)\n",
    "\n",
    "            corners2 = cv2.cornerSubPix(gray,corners,(11,11),(-1,-1),criteria)\n",
    "            imgpoints.append(corners2)\n",
    "\n",
    "            img = cv2.drawChessboardCorners(img, (10,7), corners2,ret)\n",
    "            cv2.imshow('img',img)\n",
    "            cv2.waitKey(50)\n",
    "\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1],None,None)\n",
    "    print('Intrinsic  parameters from '+ str(cameraName) + '= \\n',mtx)\n",
    "    print('Distortion parameters from '+ str(cameraName) + '= \\n',dist,'\\n')\n",
    "\n",
    "    np.save('Parameters/'+str(imgCategory)+'/'+ str(cameraName) +'/'+'intrinsic_parameters.npy', mtx)\n",
    "    np.save('Parameters/'+str(imgCategory)+'/'+ str(cameraName) +'/'+'distortion_parameters.npy', dist)\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "##Practice Images\n",
    "# callibrate_camera('Practice_Images', 'L')\n",
    "# callibrate_camera('Practice_Images', 'R')\n",
    "\n",
    "##Test Images\n",
    "#Left Camera Callibration\n",
    "callibrate_camera('Test_Images','Left_Cali')\n",
    "#Right Camera Callibration\n",
    "callibrate_camera('Test_Images','Right_Cali')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specialized-apparel",
   "metadata": {},
   "source": [
    "### Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "severe-obligation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R = \n",
      " [[ 9.99899140e-01  6.26226123e-04  1.41886351e-02]\n",
      " [-7.64301854e-04  9.99952389e-01  9.72809983e-03]\n",
      " [-1.41818676e-02 -9.73796306e-03  9.99852012e-01]] \n",
      "\n",
      "T = \n",
      " [[-20.34983933]\n",
      " [ -0.06394045]\n",
      " [ -0.6384341 ]] \n",
      "\n",
      "E = \n",
      " [[ 4.18838679e-04  6.39026355e-01 -5.77202404e-02]\n",
      " [-9.26968437e-01 -1.98565788e-01  2.03377693e+01]\n",
      " [ 7.94874244e-02 -2.03488304e+01 -1.97058041e-01]] \n",
      "\n",
      "F = \n",
      " [[-5.44824899e-09 -8.29815912e-06  3.18487500e-03]\n",
      " [ 1.20230614e-05  2.57103130e-06 -4.66834849e-01]\n",
      " [-4.31918643e-03  4.64266655e-01  1.00000000e+00]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "def find_corners(imageSet, CameraL, CameraR, chessBoardSize):    \n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "    objp = np.zeros((7*10,3), np.float32)\t\t\t\t\n",
    "    objp[:,:2] = chessBoardSize * np.mgrid[0:10,0:7].T.reshape(-1,2)\t\n",
    "\n",
    "    objpoints = [] # 3d point in real world space\n",
    "    L_imgpoints = [] # 2d points in image plane.\n",
    "    R_imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "    head_list = [str(CameraL), str(CameraR)]\n",
    "    for head in head_list:\n",
    "        imagesFolder = os.path.join(os.getcwd(),'Downloads', str(imageSet), str(head))\n",
    "        images = [ os.path.join(imagesFolder, f) for f in os.listdir('Downloads/'+str(imageSet)+'/'+str(head)) if f.endswith(\".png\") or f.endswith(\".bmp\")]\n",
    "        for pic in images:\n",
    "            img = cv2.imread(pic)\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            ret, corners = cv2.findChessboardCorners(gray, (10,7),None)\n",
    "            if ret == True:\n",
    "                corners2 = cv2.cornerSubPix(gray,corners,(11,11),(-1,-1),criteria)\n",
    "                if head == str(CameraL):\n",
    "                    objpoints.append(objp)\n",
    "                    L_imgpoints.append(corners2)\n",
    "                elif head == str(CameraR):\n",
    "                    R_imgpoints.append(corners2)\n",
    "\n",
    "                img = cv2.drawChessboardCorners(img, (10,7), corners2,ret)\n",
    "                cv2.imshow('image',img)\n",
    "                cv2.waitKey(50)\n",
    "    return objpoints, L_imgpoints, R_imgpoints, gray.shape[::-1]\n",
    "\n",
    "def  calculate_extrinsic_parameters(imageSet, CameraL, CameraR, chessBoardSize, paramL, paramR):\n",
    "    objpoints, L_imgpoints, R_imgpoints, shape = find_corners(imageSet, CameraL, CameraR, chessBoardSize)\n",
    "    L_intrinsic = np.load('Parameters/'+ str(imageSet) + '/' + str(paramL)+'/intrinsic_parameters.npy') \n",
    "    L_distortion = np.load('Parameters/'+ str(imageSet) + '/' + str(paramL)+'/distortion_parameters.npy')\n",
    "    R_intrinsic = np.load('Parameters/'+ str(imageSet) + '/' + str(paramR)+'/intrinsic_parameters.npy')\n",
    "    R_distortion = np.load('Parameters/'+ str(imageSet) + '/' + str(paramR)+'/distortion_parameters.npy')\n",
    "\n",
    "    termination_criteria_extrinsics = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 90, 1e-6)\n",
    "    # termination_criteria_extrinsics = (cv2.TERM_CRITERIA_COUNT + cv2.TERM_CRITERIA_EPS, 90, 1e-6)\n",
    "\n",
    "    rms_stereo, stereo_camera_matrix_l, stereo_dist_coeffs_l, stereo_camera_matrix_r, stereo_dist_coeffs_r, R, T, E, F = \\\n",
    "        cv2.stereoCalibrate(objpoints, L_imgpoints, R_imgpoints, L_intrinsic, L_distortion, R_intrinsic, R_distortion,  shape, criteria=termination_criteria_extrinsics, flags=cv2.CALIB_FIX_INTRINSIC)\n",
    "\n",
    "    print('R = \\n', R, '\\n')\n",
    "    print('T = \\n', T, '\\n')\n",
    "    print('E = \\n', E, '\\n')\n",
    "    print('F = \\n', F, '\\n')\n",
    "    \n",
    "    if CameraL == \"Stereo_Left\" and CameraR == \"Stereo_Right\":\n",
    "        np.save('rotation_matrix.npy', R)\n",
    "        np.save('translation_vector.npy', T)\n",
    "        np.save('essential_matrix.npy', E)\n",
    "        np.save('fundamental_matrix.npy', F)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "calculate_extrinsic_parameters(\"Test_Images\", \"Stereo_Left\", \"Stereo_Right\", 3.88, \"Left_Cali\", \"Right_Cali\")\n",
    "# calculate_extrinsic_parameters(\"Practice_Images\", \"SL\", \"SR\", 2.,\"L\", \"R\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documented-richmond",
   "metadata": {},
   "source": [
    "### Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "grave-taxation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-3cb7598ece3b>:30: DeprecationWarning: an integer is required (got type numpy.float32).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  cv2.circle(img, tuple(pt), 5, color)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from IPython.display import Image\n",
    "\n",
    "L_intrinsic = np.load('Parameters/Test_images/Left_Cali/intrinsic_parameters.npy')\n",
    "R_intrinsic = np.load('Parameters/Test_images/Left_Cali/intrinsic_parameters.npy')\n",
    "L_distortion = np.load('Parameters/Test_images/Right_Cali/distortion_parameters.npy')\n",
    "R_distortion = np.load('Parameters/Test_images/Right_Cali/distortion_parameters.npy')\n",
    "fundamental_matrix = np.load('fundamental_matrix.npy')\n",
    "\n",
    "def undistortion(name, camera_matrix, dist_coeffs):\n",
    "    img = cv2.imread(name)\n",
    "    h, w = img.shape[:2]\n",
    "    h += 1\n",
    "    w += 1\n",
    "    newcameramtx, roi = cv2.getOptimalNewCameraMatrix(camera_matrix, dist_coeffs, (w, h), 0, (w, h))\n",
    "    dst = cv2.undistort(img, camera_matrix, dist_coeffs, None, camera_matrix)\n",
    "    x, y, w, h = roi\n",
    "    dst = dst[y:y + h, x:x + w]\n",
    "    # cv2.imwrite('Undistortion' + name, dst)\n",
    "    return dst\n",
    "\n",
    "def find_corners_of_an_image(image_name, chessboard_size):\n",
    "    image = cv2.imread(image_name)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    ret, corners = cv2.findChessboardCorners(gray, chessboard_size, None)    \n",
    "    return corners.reshape(-1,2)\n",
    "\n",
    "def drawPoints(img, pts, colors):\n",
    "    for pt, color in zip(pts, colors):\n",
    "        cv2.circle(img, tuple(pt), 5, color, -1)\n",
    "\n",
    "def drawLines(img, lines, colors):\n",
    "    _, c, _ = img.shape\n",
    "    for r, color in zip(lines, colors):\n",
    "        x0, y0 = map(int, [0, -r[2]/r[1]])\n",
    "        x1, y1 = map(int, [c, -(r[2]+r[0]*c)/r[1]])\n",
    "        cv2.line(img, (x0, y0), (x1, y1), color, 1)\n",
    "\n",
    "\n",
    "undstL = undistortion('Downloads/Test_Images/Stereo_Left/L1.png', L_intrinsic, L_distortion)\n",
    "undstR = undistortion('Downloads/Test_Images/Stereo_Right/R1.png', R_intrinsic, R_distortion)\n",
    "\n",
    "imgptsL = find_corners_of_an_image('Downloads/Test_Images/Stereo_Left/L1.png', (7,10))\n",
    "imgptsR = find_corners_of_an_image('Downloads/Test_Images/Stereo_Right/R1.png', (7,10))\n",
    "\n",
    "ptsL = np.array([imgptsL[0], imgptsL[1], imgptsL[2]])\n",
    "ptsR = np.array([imgptsR[-1], imgptsR[-2], imgptsR[-3]])\n",
    "drawPoints(undstL, ptsL, (0, 0, 255))\n",
    "drawPoints(undstR, ptsR, (255, 0, 0))\n",
    "\n",
    "epilinesR = cv2.computeCorrespondEpilines(ptsR.reshape(-1, 1, 2), 2, fundamental_matrix)\n",
    "epilinesR = epilinesR.reshape(-1, 3)\n",
    "drawLines(undstL, epilinesR, (255, 0, 0))\n",
    "\n",
    "epilinesL = cv2.computeCorrespondEpilines(ptsL.reshape(-1, 1, 2), 1, fundamental_matrix)\n",
    "epilinesL = epilinesL.reshape(-1, 3)\n",
    "drawLines(undstR, epilinesL, (0, 0, 255))\n",
    "\n",
    "img = cv2.hconcat([undstL, undstR])\n",
    "cv2.imshow('Epipolar_lines',img)\n",
    "cv2.imwrite('Epipolar_lines.jpg',img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "therapeutic-environment",
   "metadata": {},
   "source": [
    "![](C:/Users/kavin/Documents/CODE/ECEN_631/Assignment_3/Epipolar_lines.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "casual-shadow",
   "metadata": {},
   "source": [
    "### Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "tamil-outdoors",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "L_intrinsic = np.load('Parameters/Test_images/Left_Cali/intrinsic_parameters.npy')\n",
    "R_intrinsic = np.load('Parameters/Test_images/Left_Cali/intrinsic_parameters.npy')\n",
    "L_distortion = np.load('Parameters/Test_images/Right_Cali/distortion_parameters.npy')\n",
    "R_distortion = np.load('Parameters/Test_images/Right_Cali/distortion_parameters.npy')\n",
    "cameraParameters = [ L_intrinsic, L_distortion, R_intrinsic, R_distortion]\n",
    "\n",
    "rotation_matrix = np.load('rotation_matrix.npy')\n",
    "translation_vector = np. load('translation_vector.npy')\n",
    "pose = [ rotation_matrix, translation_vector]\n",
    "\n",
    "def compute_stereo_rectification_maps(imgLName, imgRName, camParams, PoseParams):\n",
    "    imgL = cv2.imread(imgLName)\n",
    "    imgR = cv2.imread(imgRName)\n",
    "    h, w = imgL.shape[:2]\n",
    "    imgSize = (w, h)\n",
    "\n",
    "    R1, R2, P1, P2, Q, roi1, roi2 = cv2.stereoRectify(camParams[0], camParams[1], camParams[2], camParams[3],\n",
    "                                                      imgSize, PoseParams[0], PoseParams[1])\n",
    "    map1x, map1y = cv2.initUndistortRectifyMap(camParams[0], camParams[1], R1, P1, imgSize, cv2.CV_32FC1)\n",
    "    map2x, map2y = cv2.initUndistortRectifyMap(camParams[2], camParams[3], R2, P2, imgSize, cv2.CV_32FC1)\n",
    "\n",
    "    remapL = cv2.remap(imgL, map1x, map1y, cv2.INTER_LINEAR)\n",
    "    remapY = cv2.remap(imgL, map2x, map2y, cv2.INTER_LINEAR)\n",
    "    return remapL, remapY\n",
    "\n",
    "def Difference(imagename_ori, remap):\n",
    "    img_ori = cv2.imread(imagename_ori)\n",
    "    gray1 = cv2.cvtColor(img_ori, cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.cvtColor(remap, cv2.COLOR_BGR2GRAY)\n",
    "    diff = cv2.absdiff(gray1, gray2)\n",
    "    return diff\n",
    "\n",
    "imgL = 'Downloads/Test_Images/Stereo_Left/L1.png'\n",
    "imgR = 'Downloads/Test_Images/Stereo_Right/R1.png'\n",
    "\n",
    "remapL, remapR = compute_stereo_rectification_maps(imgL, imgR, cameraParameters, pose)\n",
    "diffL = Difference(imgL, remapL)\n",
    "diffR = Difference(imgR, remapR)\n",
    "\n",
    "diffLC = cv2.cvtColor(diffL, cv2.COLOR_GRAY2BGR)\n",
    "diffRC = cv2.cvtColor(diffR, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "for y in range(20):\n",
    "    cv2.line(remapL, (0, y*32), (640, y*32), (0, 0, 255), 1)\n",
    "    cv2.line(remapR, (0, y*32), (640, y*32), (0, 0, 255), 1)\n",
    "hor1 = cv2.hconcat([remapL, remapR])\n",
    "hor2 = cv2.hconcat([diffLC, diffRC])\n",
    "finalImg = cv2.vconcat([hor1, hor2])\n",
    "cv2.imshow('Task_4', finalImg)\n",
    "cv2.imwrite('Task_4.jpg', finalImg)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latest-swaziland",
   "metadata": {},
   "source": [
    "![](C:/Users/kavin/Documents/CODE/ECEN_631/Assignment_3/Task_4.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smart-advocacy",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
